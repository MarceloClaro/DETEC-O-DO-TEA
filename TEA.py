# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aDop73YQxlbj1oCJpTc4yX9ap1N-tw_9
"""
import streamlit as st
import numpy as np
import pandas as pd
import os
import zipfile
from PIL import Image
import tensorflow as tf
import time 
import matplotlib
matplotlib.use('agg')  
import matplotlib.pyplot as plt


# Crie uma função para gerar o autoencoder
def createAutoencoder():
    # Obter o conjunto de dados
    from tensorflow.keras.datasets import mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    
    # Normalizar os dados
    x_train = x_train.astype('float32')/255.
    x_test = x_test.astype('float32')/255.
    
    # Remodelar imagens de 28x28 para 32x32
    x_train = np.pad(x_train,((0,0),(2,2),(2,2)),'constant', constant_values=0)
    x_test = np.pad(x_test,((0,0),(2,2),(2,2)), 'constant', constant_values=0)
    
    # Criar o modelo
    autoencoder = tf.keras.models.Sequential([tf.keras.layers.InputLayer(input_shape=(32, 32, 1)),
                                              tf.keras.layers.Conv2D(16,(3,3), activation='relu', padding='same'), 
                                              tf.keras.layers.MaxPooling2D(pool_size=(2,2)), 
                                              tf.keras.layers.Conv2D(8,(3,3), activation='relu', padding='same'), 
                                              tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
                                              tf.keras.layers.Conv2D(8,(3,3), activation='relu', padding='same'),                                            
                                              tf.keras.layers.UpSampling2D(),
                                              tf.keras.layers.Conv2D(16,(3,3), activation='relu', padding='same'),
                                              tf.keras.layers.UpSampling2D(),
                                              tf.keras.layers.Conv2D(1,(3,3), activation='sigmoid', padding='same')]) 
    
    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
    autoencoder.summary()
    
    # Remodelar os dados para caber no modelo
    x_train = x_train.reshape(-1, 28, 28, 1)
    x_test = x_test.reshape(-1, 28, 28, 1)
    
    # Treine o modelo e salve-o
    autoencoder.fit(x_train, x_train, epochs=10, batch_size=128,
                    shuffle=True, validation_data=(x_test, x_test))
    autoencoder.save_weights('./autoencoder_mnist.h5')
    
# Crie uma função para carregar o conjunto de dados
def downloadAndUnzip():
    filename = 'AutData.zip'

    if not os.path.exists(filename):
      os.system('wget https://drive.google.com/file/d/14zeNkO1cHKnCEa-pFwnZVB4yk3MKu8XJ/view?usp=sharing')
      os.system('unzip AutData.zip')      
      os.system('mv AutData.zip AutData')
      os.system('rm AutData.zip')

# Crie uma função para carregar as imagens
def loadImages():
    img_data =[]
    labels =[]

    #Load Autistic Images
    autistic_images_list = os.listdir('./AutData/NonAutData/')
    autistic_path = './AutData/AutData/'
    for autistic_img in autistic_images_list:
        labels.append(1)
        img = Image.open(autistic_path+autistic_img).convert('L')
        img_data.append(np.array(img))
    
    #Carregar imagens não autistas
    non_autistic_images_list = os.listdir('./AutData/NonAutData/')
    non_autistic_path = './AutData/NonAutData/'
    for non_autistic_img in non_autistic_images_list:
        labels.append(2)
        img = Image.open(non_autistic_path+non_autistic_img).convert('L')
        img_data.append(np.array(img))
    
    # Remodelar imagens
    img_data = np.array(img_data).reshape(-1, 28, 28, 1).astype('float16')

    # Normalizar os dados
    img_data /= 255.
    return img_data, labels

# Criar uma função para construir o modelo
def buildModel():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(2, activation='softmax')
    ])
    model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
    return model

#
def plotGraph(history):
# Gráfico de precisão vs. épocas
    acc = history.history['accuracy']
    epochs = range(len(acc))
    fig = plt.figure(figsize=(7,4))
    plt.plot(epochs, acc)
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    return st.pyplot(fig)

#
def plotResults():
    # Plotar resultados de precisão
    plt.figure(figsize=(16, 6))
    plt.subplot(1, 2, 1)
    sns.heatmap(cm_test, annot=True, cmap="Blues", fmt="d", 
                xticklabels=class_names, 
                yticklabels=class_names)
    plt.title("Confusion Matrix - Test Set")
    plt.xlabel("Predicted label")
    plt.ylabel("True label")

    # Plotar resultados de precisão
    plt.subplot(1, 2, 2)
    sns.heatmap(cm_train, annot=True, cmap="Blues", fmt="d", 
                xticklabels=class_names, 
                yticklabels=class_names)
    plt.title("Confusion Matrix - Train Set")
    plt.xlabel("Predicted label")
    plt.ylabel("True label")

# Crie uma função principal
def main():
    st.title('Image Classification using Neural Networks')

    # Crie um menu lateral
    st.sidebar.header('Autism Image Classification')
    menu = ["Download & Unzip", "Create Autoencoder","Train Model and Classify Images","Results & Conclusions"]
    choice = st.sidebar.selectbox("Menu", menu)

    # Baixe e descompacte o conjunto de dados
    if choice == "Download & Unzip":
        with st.spinner('Baixando e descompactando o conjunto de dados...'):
            time.sleep(3)
            st.success('Baixe e descompacte com sucesso!')
            downloadAndUnzip()


    # Criar um autoencoder CNN
    if choice == "Create Autoencoder":
        st.subheader('Create Autoencoder using Convolutional Neural Networks')
        st.write('An autoencoder is an unsupervised machine learning algorithm that takes an input image and encodes it into a set of features, which can be used to reconstruct the original input.')
        option = st.selectbox("Options",["Create Autoencoder","View Summary of Autoencoder Model"])

        # Criar um codificador automático
        if option == "Create Autoencoder":
            with st.spinner('Creating autoencoder...'):
                time.sleep(3)
                st.success('Autoencoder created successfully!')
                createAutoencoder()

        
        # Exibir o resumo do codificador automático
        if option == "View Summary of Autoencoder Model":
            st.write(tf.keras.models.load_model('autoencoder_mnist.h5').summary())


    # Treine o modelo e classifique as imagens
    if choice == "Train Model and Classify Images":
        st.subheader('Train Model and Classify Images')
        option = st.radio("Options",("Train Model","Classify Images"))

        # Treine o modelo
        if option == "Train Model":
            # Carregar os dados
            img_data, labels = loadImages()

            # Divida os dados
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(img_data, labels,
                                                            random_state=1,
                                                            test_size = 0.2)

            # Create the model
            model = buildModel()

            # Treine o modelo
            with st.spinner('Training model...'):
                time.sleep(3)
            history = model.fit(X_train, y_train,
                        epochs=10,
                        validation_data=(X_test, y_test))

            plotGraph(history)
            st.success("Model trained successfully!")


        # Classificar imagens
        if option == "Classify Images":
            # Carregar uma nova imagem
            newImage = st.file_uploader("Upload an Image", type="jpg")

            # prever a classe
            if newImage is not None:
                with st.spinner('Classifying image...'):
                    time.sleep(3)
                newImage = Image.open(newImage).convert('L')
                
                # Remodele a imagem
                img = np.array(newImage).reshape(-1, 28, 28, 1).astype('float16')

                 # Normalizar os dados
                img /= 255.
                
                # Carregar o modelo
                model = buildModel()
                model.load_weights('autoencoder_mnist.h5')
                probabilities = model.predict(img)
                
                # Obter a classe
                if np.argmax(probabilities) == 0:
                    class_name = 'Autistic'
                else:
                    class_name = 'Non-autistic'
                st.write('The image is classified as: ', class_name)
                st.success('Classification successful!')


    # Mostrar resultados e conclusões
    if choice == "Results & Conclusions":
        st.subheader('Classification Results & Conclusions')

        # matriz de confusão
        from sklearn.metrics import confusion_matrix
        cm_test = confusion_matrix(y_test, y_pred_test)
        cm_train = confusion_matrix(y_train, y_pred_train)

        # Obtenha os nomes das classes
        class_names = ['Autistic','Non-autistic']

        # matriz de confusão
        plotResults()

        # Precisões
        st.write('The testing accuracy is: %.2f' % accuracy_test)
        st.write('The training accuracy is: %.2f' % accuracy_train)

        # Conclusões
        st.write('The results obtained show that the autoencoder was able to classify images with an accuracy of %.2f on the test set and %.2f on the train set.' % (accuracy_test, accuracy_train))

if __name__ == '__main__':
    main()
